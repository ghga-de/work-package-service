{
  "additionalProperties": false,
  "description": "Modifies the original Settings class provided by the user",
  "properties": {
    "enable_opentelemetry": {
      "default": false,
      "description": "If set to true, this will run necessary setup code.If set to false, environment variables are set that should also effectively disable autoinstrumentation.",
      "title": "Enable Opentelemetry",
      "type": "boolean"
    },
    "otel_trace_sampling_rate": {
      "default": 1.0,
      "description": "Determines which proportion of spans should be sampled. A value of 1.0 means all and is equivalent to the previous behaviour. Setting this to 0 will result in no spans being sampled, but this does not automatically set `enable_opentelemetry` to False.",
      "maximum": 1,
      "minimum": 0,
      "title": "Otel Trace Sampling Rate",
      "type": "number"
    },
    "otel_exporter_protocol": {
      "default": "http/protobuf",
      "description": "Specifies which protocol should be used by exporters.",
      "enum": [
        "grpc",
        "http/protobuf"
      ],
      "title": "Otel Exporter Protocol",
      "type": "string"
    },
    "otel_exporter_endpoint": {
      "description": "Base endpoint URL for the collector that receives content from the exporter.",
      "examples": [
        "http://localhost:4318"
      ],
      "format": "uri",
      "minLength": 1,
      "title": "Otel Exporter Endpoint",
      "type": "string"
    },
    "log_level": {
      "default": "INFO",
      "description": "The minimum log level to capture.",
      "enum": [
        "CRITICAL",
        "ERROR",
        "WARNING",
        "INFO",
        "DEBUG",
        "TRACE"
      ],
      "title": "Log Level",
      "type": "string"
    },
    "service_name": {
      "default": "wps",
      "title": "Service Name",
      "type": "string"
    },
    "service_instance_id": {
      "description": "A string that uniquely identifies this instance across all instances of this service. A globally unique Kafka client ID will be created by concatenating the service_name and the service_instance_id.",
      "examples": [
        "germany-bw-instance-001"
      ],
      "title": "Service Instance Id",
      "type": "string"
    },
    "log_format": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "If set, will replace JSON formatting with the specified string format. If not set, has no effect. In addition to the standard attributes, the following can also be specified: timestamp, service, instance, level, correlation_id, and details",
      "examples": [
        "%(timestamp)s - %(service)s - %(level)s - %(message)s",
        "%(asctime)s - Severity: %(levelno)s - %(msg)s"
      ],
      "title": "Log Format"
    },
    "log_traceback": {
      "default": true,
      "description": "Whether to include exception tracebacks in log messages.",
      "title": "Log Traceback",
      "type": "boolean"
    },
    "datasets_collection": {
      "default": "datasets",
      "description": "The name of the database collection for datasets",
      "title": "Datasets Collection",
      "type": "string"
    },
    "work_packages_collection": {
      "default": "workPackages",
      "description": "The name of the database collection for work packages",
      "title": "Work Packages Collection",
      "type": "string"
    },
    "work_package_valid_days": {
      "default": 30,
      "description": "How many days a work package (and its access token) stays valid",
      "title": "Work Package Valid Days",
      "type": "integer"
    },
    "work_package_signing_key": {
      "description": "The private key for signing work order tokens",
      "examples": [
        "{\"crv\": \"P-256\", \"kty\": \"EC\", \"x\": \"...\", \"y\": \"...\"}"
      ],
      "format": "password",
      "title": "Work Package Signing Key",
      "type": "string",
      "writeOnly": true
    },
    "mongo_dsn": {
      "description": "MongoDB connection string. Might include credentials. For more information see: https://naiveskill.com/mongodb-connection-string/",
      "examples": [
        "mongodb://localhost:27017"
      ],
      "format": "multi-host-uri",
      "minLength": 1,
      "title": "Mongo Dsn",
      "type": "string"
    },
    "db_name": {
      "default": "work-packages",
      "title": "Db Name",
      "type": "string"
    },
    "mongo_timeout": {
      "anyOf": [
        {
          "exclusiveMinimum": 0,
          "type": "integer"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Timeout in seconds for API calls to MongoDB. The timeout applies to all steps needed to complete the operation, including server selection, connection checkout, serialization, and server-side execution. When the timeout expires, PyMongo raises a timeout exception. If set to None, the operation will not time out (default MongoDB behavior).",
      "examples": [
        300,
        600,
        null
      ],
      "title": "Mongo Timeout"
    },
    "kafka_servers": {
      "description": "A list of connection strings to connect to Kafka bootstrap servers.",
      "examples": [
        [
          "localhost:9092"
        ]
      ],
      "items": {
        "type": "string"
      },
      "title": "Kafka Servers",
      "type": "array"
    },
    "kafka_security_protocol": {
      "default": "PLAINTEXT",
      "description": "Protocol used to communicate with brokers. Valid values are: PLAINTEXT, SSL.",
      "enum": [
        "PLAINTEXT",
        "SSL"
      ],
      "title": "Kafka Security Protocol",
      "type": "string"
    },
    "kafka_ssl_cafile": {
      "default": "",
      "description": "Certificate Authority file path containing certificates used to sign broker certificates. If a CA is not specified, the default system CA will be used if found by OpenSSL.",
      "title": "Kafka Ssl Cafile",
      "type": "string"
    },
    "kafka_ssl_certfile": {
      "default": "",
      "description": "Optional filename of client certificate, as well as any CA certificates needed to establish the certificate's authenticity.",
      "title": "Kafka Ssl Certfile",
      "type": "string"
    },
    "kafka_ssl_keyfile": {
      "default": "",
      "description": "Optional filename containing the client private key.",
      "title": "Kafka Ssl Keyfile",
      "type": "string"
    },
    "kafka_ssl_password": {
      "default": "",
      "description": "Optional password to be used for the client private key.",
      "format": "password",
      "title": "Kafka Ssl Password",
      "type": "string",
      "writeOnly": true
    },
    "generate_correlation_id": {
      "default": true,
      "description": "A flag, which, if False, will result in an error when inbound requests don't possess a correlation ID. If True, requests without a correlation ID will be assigned a newly generated ID in the correlation ID middleware function.",
      "examples": [
        true,
        false
      ],
      "title": "Generate Correlation Id",
      "type": "boolean"
    },
    "kafka_max_message_size": {
      "default": 1048576,
      "description": "The largest message size that can be transmitted, in bytes, before compression. Only services that have a need to send/receive larger messages should set this. When used alongside compression, this value can be set to something greater than the broker's `message.max.bytes` field, which effectively concerns the compressed message size.",
      "examples": [
        1048576,
        16777216
      ],
      "exclusiveMinimum": 0,
      "title": "Kafka Max Message Size",
      "type": "integer"
    },
    "kafka_compression_type": {
      "anyOf": [
        {
          "enum": [
            "gzip",
            "snappy",
            "lz4",
            "zstd"
          ],
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The compression type used for messages. Valid values are: None, gzip, snappy, lz4, and zstd. If None, no compression is applied. This setting is only relevant for the producer and has no effect on the consumer. If set to a value, the producer will compress messages before sending them to the Kafka broker. If unsure, zstd provides a good balance between speed and compression ratio.",
      "examples": [
        null,
        "gzip",
        "snappy",
        "lz4",
        "zstd"
      ],
      "title": "Kafka Compression Type"
    },
    "kafka_max_retries": {
      "default": 0,
      "description": "The maximum number of times to immediately retry consuming an event upon failure. Works independently of the dead letter queue.",
      "examples": [
        0,
        1,
        2,
        3,
        5
      ],
      "minimum": 0,
      "title": "Kafka Max Retries",
      "type": "integer"
    },
    "kafka_enable_dlq": {
      "default": false,
      "description": "A flag to toggle the dead letter queue. If set to False, the service will crash upon exhausting retries instead of publishing events to the DLQ. If set to True, the service will publish events to the DLQ topic after exhausting all retries",
      "examples": [
        true,
        false
      ],
      "title": "Kafka Enable DLQ",
      "type": "boolean"
    },
    "kafka_dlq_topic": {
      "default": "dlq",
      "description": "The name of the topic used to resolve error-causing events.",
      "examples": [
        "dlq"
      ],
      "title": "Kafka DLQ Topic",
      "type": "string"
    },
    "kafka_retry_backoff": {
      "default": 0,
      "description": "The number of seconds to wait before retrying a failed event. The backoff time is doubled for each retry attempt.",
      "examples": [
        0,
        1,
        2,
        3,
        5
      ],
      "minimum": 0,
      "title": "Kafka Retry Backoff",
      "type": "integer"
    },
    "dataset_change_topic": {
      "description": "Name of the topic announcing, among other things, the list of files included in a new dataset.",
      "examples": [
        "metadata_datasets"
      ],
      "title": "Dataset Change Topic",
      "type": "string"
    },
    "dataset_deletion_type": {
      "description": "Type used for events announcing a new dataset overview.",
      "examples": [
        "dataset_deleted"
      ],
      "title": "Dataset Deletion Type",
      "type": "string"
    },
    "dataset_upsertion_type": {
      "description": "Type used for events announcing a new dataset overview.",
      "examples": [
        "dataset_created"
      ],
      "title": "Dataset Upsertion Type",
      "type": "string"
    },
    "download_access_url": {
      "description": "URL pointing to the internal download access API.",
      "examples": [
        "http://127.0.0.1/download-access"
      ],
      "title": "Download Access Url",
      "type": "string"
    },
    "auth_key": {
      "description": "The GHGA internal public key for validating the token signature.",
      "examples": [
        "{\"crv\": \"P-256\", \"kty\": \"EC\", \"x\": \"...\", \"y\": \"...\"}"
      ],
      "title": "Internal public key",
      "type": "string"
    },
    "auth_algs": {
      "default": [
        "ES256"
      ],
      "description": "A list of all algorithms used for signing GHGA internal tokens.",
      "items": {
        "type": "string"
      },
      "title": "Auth Algs",
      "type": "array"
    },
    "auth_check_claims": {
      "additionalProperties": true,
      "default": {
        "id": null,
        "name": null,
        "email": null,
        "iat": null,
        "exp": null
      },
      "description": "A dict of all GHGA internal claims that shall be verified.",
      "title": "Auth Check Claims",
      "type": "object"
    },
    "auth_map_claims": {
      "additionalProperties": {
        "type": "string"
      },
      "default": {},
      "description": "A mapping of claims to attributes in the GHGA auth context.",
      "title": "Auth Map Claims",
      "type": "object"
    },
    "host": {
      "default": "127.0.0.1",
      "description": "IP of the host.",
      "title": "Host",
      "type": "string"
    },
    "port": {
      "default": 8080,
      "description": "Port to expose the server on the specified host",
      "title": "Port",
      "type": "integer"
    },
    "auto_reload": {
      "default": false,
      "description": "A development feature. Set to `True` to automatically reload the server upon code changes",
      "title": "Auto Reload",
      "type": "boolean"
    },
    "workers": {
      "default": 1,
      "description": "Number of workers processes to run.",
      "title": "Workers",
      "type": "integer"
    },
    "api_root_path": {
      "default": "",
      "description": "Root path at which the API is reachable. This is relative to the specified host and port.",
      "title": "Api Root Path",
      "type": "string"
    },
    "openapi_url": {
      "default": "/openapi.json",
      "description": "Path to get the openapi specification in JSON format. This is relative to the specified host and port.",
      "title": "Openapi Url",
      "type": "string"
    },
    "docs_url": {
      "default": "/docs",
      "description": "Path to host the swagger documentation. This is relative to the specified host and port.",
      "title": "Docs Url",
      "type": "string"
    },
    "cors_allowed_origins": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "A list of origins that should be permitted to make cross-origin requests. By default, cross-origin requests are not allowed. You can use ['*'] to allow any origin.",
      "examples": [
        [
          "https://example.org",
          "https://www.example.org"
        ]
      ],
      "title": "Cors Allowed Origins"
    },
    "cors_allow_credentials": {
      "anyOf": [
        {
          "type": "boolean"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Indicate that cookies should be supported for cross-origin requests. Defaults to False. Also, cors_allowed_origins cannot be set to ['*'] for credentials to be allowed. The origins must be explicitly specified.",
      "examples": [
        [
          "https://example.org",
          "https://www.example.org"
        ]
      ],
      "title": "Cors Allow Credentials"
    },
    "cors_allowed_methods": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "A list of HTTP methods that should be allowed for cross-origin requests. Defaults to ['GET']. You can use ['*'] to allow all standard methods.",
      "examples": [
        [
          "*"
        ]
      ],
      "title": "Cors Allowed Methods"
    },
    "cors_allowed_headers": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "A list of HTTP request headers that should be supported for cross-origin requests. Defaults to []. You can use ['*'] to allow all headers. The Accept, Accept-Language, Content-Language and Content-Type headers are always allowed for CORS requests.",
      "examples": [
        []
      ],
      "title": "Cors Allowed Headers"
    }
  },
  "required": [
    "otel_exporter_endpoint",
    "service_instance_id",
    "work_package_signing_key",
    "mongo_dsn",
    "kafka_servers",
    "dataset_change_topic",
    "dataset_deletion_type",
    "dataset_upsertion_type",
    "download_access_url",
    "auth_key"
  ],
  "title": "ModSettings",
  "type": "object"
}